import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder


# # members_encoded.csv íŒŒì¼ ë¡œë“œ
# df_members = pd.read_csv('./data/members_encoded.csv')

# # msnoì™€ msno_encoded ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë§¤í•‘ ë§Œë“¤ê¸°
# msno_mapping = dict(zip(df_members['msno'], df_members['msno_encoded']))

# # ëŒ€ìš©ëŸ‰ CSVë¥¼ ë¶„í•  ì²˜ë¦¬í•  í¬ê¸° (ë©”ëª¨ë¦¬ 16ê¸°ê°€ë©´ ë°±ë§Œ, 32ê¸°ê°€ë©´ 3ë°±ë§Œ ê¹Œì§€ ì—¬ìœ ë¡œì›€)
# chunk_size = 1_000_000  

# # CSVë¥¼ append ëª¨ë“œë¡œ ì €ì¥í•˜ê¸° ìœ„í•´ ì²˜ìŒ íŒŒì¼ ìƒì„±
# first_chunk = True  

# i = 15
# # for i in range(16,20):
#     # ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ í•œ ë²ˆì— ë‹¤ ì½ì§€ ì•Šê³  ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬
# for chunk in pd.read_csv(f"./data/user_logs_{i}.csv", chunksize=chunk_size):
#     print(chunk.columns)
#     chunk['msno'] = chunk['msno'].map(msno_mapping).astype('Int64')  # msnoë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    
#     # ë³€í™˜ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ì²« ë²ˆì§¸ ë°˜ë³µì—ì„œëŠ” í—¤ë” í¬í•¨, ì´í›„ì—ëŠ” ìƒëµ)
#     chunk.to_csv(f"./data/user_logs_encoded{i}", index=False, mode='w' if first_chunk else 'a', header=first_chunk)
        
#     first_chunk = False  # ì´í›„ì—ëŠ” 'append' ëª¨ë“œë¡œ ì €ì¥


# # íŒë‹¤ìŠ¤ì—ì„œ ì‹¤í–‰í• ë ¤ë©´ íŒŒì¼ í¬ê¸°ê°€ 2GB ì œí•œ
# chunk_size = 50_000_000  
# file_index = 1  # íŒŒì¼ ë²ˆí˜¸

# for chunk in pd.read_csv("./data/user_logs_encoded.csv", chunksize=chunk_size):
#     output_file = f"./data/user_logs_encoded_part{file_index}.csv"
#     chunk.to_csv(output_file, index=False)

#     print(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")  # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
#     file_index += 1  # ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ ì¦ê°€

# print('íŒŒì¼ ë¶„í•  ì™„ë£Œ!')


# # ë³€í™˜í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸
# file_list = [f"./data/user_logs_encoded_part{i}.csv" for i in range(1, 9)]

# for file in file_list:
#     # CSV íŒŒì¼ ì½ê¸°
#     df = pd.read_csv(file)

#     # msno ì»¬ëŸ¼ì„ Int64ë¡œ ë³€í™˜
#     df['msno'] = df['msno'].astype('Int64')

#     # ë‹¤ì‹œ ì €ì¥ (ë®ì–´ì“°ê¸°)
#     df.to_csv(file, index=False)

#     print(f"ë³€í™˜ ì™„ë£Œ: {file}")

# print("ëª¨ë“  íŒŒì¼ì˜ msnoë¥¼ Int64ë¡œ ë³€í™˜ ì™„ë£Œ!")





# ë³€í™˜í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸
file_list = [f"./data/user_logs_encoded{i}.csv" for i in range(13, 20)]

i=13
for file in file_list:
    # msnoë³„ ë°ì´í„°ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
    
    aggregated_data = {}
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(file)
    df = df.drop(columns=['num_unq'],errors='ignore')

    # msno ì»¬ëŸ¼ì„ Int64ë¡œ ë³€í™˜
    df['msno'] = df['msno'].astype('Int64')

    # ë‹¤ì‹œ ì €ì¥ (ë®ì–´ì“°ê¸°)
    df.to_csv(file, index=False)

    print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file}")

    # CSV íŒŒì¼ ì½ê¸° (ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬)
    for chunk in pd.read_csv(file, chunksize=3_000_000):  # ì²­í¬ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥
        # msno ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë°ì´í„° í•©ì‚°
        grouped = chunk.groupby("msno").agg(
            num_25=("num_25", "sum"),
            num_50=("num_50", "sum"),
            num_75=("num_75", "sum"),
            num_985=("num_985", "sum"),
            num_100=("num_100", "sum"),
            total_secs=("total_secs", "sum"),
            use_date=("date", "count"),  # ë‚ ì§œ ê°œìˆ˜
            start_date=("date", "min"),  # ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œ
            end_date=("date", "max")  # ê°€ì¥ ë§ˆì§€ë§‰ ë‚ ì§œ
        ).reset_index()

        # ğŸ— ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©í•˜ì—¬ ëˆ„ì  (ë”•ì…”ë„ˆë¦¬ë¥¼ í™œìš©í•œ ë³‘í•©)
        for row in grouped.itertuples(index=False):
            msno = row.msno
            if msno in aggregated_data:
                aggregated_data[msno]["num_25"] += row.num_25
                aggregated_data[msno]["num_50"] += row.num_50
                aggregated_data[msno]["num_75"] += row.num_75
                aggregated_data[msno]["num_985"] += row.num_985
                aggregated_data[msno]["num_100"] += row.num_100
                aggregated_data[msno]["total_secs"] = row.total_secs
                aggregated_data[msno]["use_date"] += row.use_date  # ë‚ ì§œ ê°œìˆ˜ ëˆ„ì 
                aggregated_data[msno]["start_date"] = min(aggregated_data[msno]["start_date"], row.start_date)
                aggregated_data[msno]["end_date"] = max(aggregated_data[msno]["end_date"], row.end_date)
            else:
                aggregated_data[msno] = {
                    "num_25": row.num_25,
                    "num_50": row.num_50,
                    "num_75": row.num_75,
                    "num_985": row.num_985,
                    "num_100": row.num_100,
                    "total_secs": row.total_secs,
                    "use_date": row.use_date,       # ì´ˆê¸°í™”
                    "start_date": row.start_date,
                    "end_date": row.end_date
                }
    
    # ë”•ì…”ë„ˆë¦¬ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (msnoë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ìœ ì§€)
    df_final = pd.DataFrame.from_dict(aggregated_data, orient="index")

    # msnoë¥¼ ì¼ë°˜ ì»¬ëŸ¼ìœ¼ë¡œ ìœ ì§€í•˜ê³  ì¸ë±ìŠ¤ ì œê±°
    df_final.index.name = "msno"
    df_final.reset_index(inplace=True)

    # CSV íŒŒì¼ë¡œ ì €ì¥ (ì¸ë±ìŠ¤ ì—†ì´)
    df_final.to_csv(f"./data/user_logs{i}.csv", index=False)
    i=i+1

    print(f"ë³€í™˜ ì™„ë£Œ: {file}")

print("ì €ì¥ ì™„ë£Œ")